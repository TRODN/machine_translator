{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "nlp-assignment-bigru.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "papermill": {
          "duration": 1.88717,
          "end_time": "2021-04-02T05:53:28.447231",
          "exception": false,
          "start_time": "2021-04-02T05:53:26.560061",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "qOjzDonJYwQm"
      },
      "source": [
        "import collections\n",
        "import csv\n",
        "import math\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import random\n",
        "import re\n",
        "import time\n",
        "import torch\n",
        "\n",
        "from functools import partial\n",
        "from operator import is_not\n",
        "\n",
        "from torch.utils import data\n",
        "from torch import nn\n",
        "\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "28hb0ImNYwQ1"
      },
      "source": [
        "def train_validation_split(csv_file):\n",
        "    \"\"\"For split csv file in train validation set and save these sets in file\"\"\"\n",
        "    Hindi_sts = [] \n",
        "    Eng_sts = []\n",
        "    with open(csv_file, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        for row in reader:\n",
        "            if(row[0] == ''):\n",
        "                continue\n",
        "            Hindi_sts.append(row[1])\n",
        "            Eng_sts.append(row[2])\n",
        "\n",
        "    trn_len = int(102322*0.8)\n",
        "    tst_len = 102322 - trn_len    \n",
        "    tst_idxs = random.sample(range(102322), tst_len)\n",
        "\n",
        "    X_validate = []\n",
        "    y_validate = []\n",
        "    for idx in tst_idxs:\n",
        "        X_validate.append(Hindi_sts[idx])\n",
        "        y_validate.append(Eng_sts[idx])\n",
        "\n",
        "    set1 = set(range(102322))\n",
        "    set2 = set(tst_idxs)\n",
        "    trn_idxs = list(set1 - set2)\n",
        "\n",
        "    X_train = []\n",
        "    y_train = []\n",
        "    for idx in trn_idxs:\n",
        "        X_train.append(Hindi_sts[idx])\n",
        "        y_train.append(Eng_sts[idx])\n",
        "    \n",
        "    with open('X_train.txt', 'w') as f, open('y_train.txt', 'w') as f1:\n",
        "        for row1,row2 in zip(X_train, y_train):\n",
        "            f.write(row1 + '\\n')\n",
        "            f1.write(row2 + '\\n')\n",
        "\n",
        "    with open('X_validate.txt', 'w') as f, open('y_validate.txt', 'w') as f1:\n",
        "        for row1,row2 in zip(X_validate, y_validate):\n",
        "            f.write(row1 + '\\n')\n",
        "            f1.write(row2 + '\\n')\n",
        "\n",
        "csv_file = '../input/hineng/train/train.csv'\n",
        "train_validation_split(csv_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpbt3hgPYwQ3"
      },
      "source": [
        "References for below code:\n",
        "http://d2l.ai/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tmEUypDEYwQ4"
      },
      "source": [
        "def tokenize_hin(X_train):\n",
        "    \"\"\"For tokenizing hindi statements\"\"\"\n",
        "    source_tokenize = []\n",
        "    for s in X_train:\n",
        "        s = re.sub(r'[^\\u0970-\\u097f\\u0900-\\u0963]+', ' ', s).split(' ')\n",
        "        s = [x for x in s if x is not '']\n",
        "        source_tokenize.append(s)    \n",
        "    return source_tokenize\n",
        "\n",
        "def tokenize_eng(y_train):\n",
        "    \"\"\"For tokenizing english statements\"\"\"\n",
        "    target_tokenize = []\n",
        "    for s in y_train:\n",
        "        s = s.lower()\n",
        "        s = re.sub(r'[^a-zA-Z]+', ' ', s).split(' ')\n",
        "        s = [x for x in s if x is not '']\n",
        "        target_tokenize.append(s)\n",
        "    return target_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rwYpwjVNYwQ5"
      },
      "source": [
        "class Accumulator:\n",
        "    \"\"\"For accumulating sums over `n` variables.\"\"\"\n",
        "    def __init__(self, n):\n",
        "        self.data = [0.0] * n\n",
        "\n",
        "    def add(self, *args):\n",
        "        self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "\n",
        "    def reset(self):\n",
        "        self.data = [0.0] * len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.033152,
          "end_time": "2021-04-02T05:53:28.583698",
          "exception": false,
          "start_time": "2021-04-02T05:53:28.550546",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "BFg2O6LhYwQ6"
      },
      "source": [
        "class Vocab:\n",
        "    \"\"\"Vocabulary for text.\"\"\"\n",
        "    def __init__(self, tokens=None, min_freq=0 , reserved_tokens=None):\n",
        "        if tokens is None:\n",
        "            tokens = []\n",
        "        if reserved_tokens is None:\n",
        "            reserved_tokens = []\n",
        "        \n",
        "        # Sort according to frequencies\n",
        "        counter = count_corpus(tokens)\n",
        "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1], reverse=True)\n",
        "        # The index for the unknown token is 0\n",
        "        self.unk, uniq_tokens = 0, ['<unk>'] + reserved_tokens\n",
        "        uniq_tokens += [\n",
        "            token for token, freq in self.token_freqs\n",
        "            if freq >= min_freq and token not in uniq_tokens]\n",
        "        self.idx_to_token, self.token_to_idx = [], dict()\n",
        "        for token in uniq_tokens:\n",
        "            self.idx_to_token.append(token)\n",
        "            self.token_to_idx[token] = len(self.idx_to_token) - 1\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx_to_token)\n",
        "\n",
        "    def __getitem__(self, tokens):\n",
        "        if not isinstance(tokens, (list, tuple)):\n",
        "            return self.token_to_idx.get(tokens, self.unk)\n",
        "        return [self.__getitem__(token) for token in tokens]\n",
        "\n",
        "    def to_tokens(self, indices):\n",
        "        if not isinstance(indices, (list, tuple)):\n",
        "            return self.idx_to_token[indices]\n",
        "        return [self.idx_to_token[index] for index in indices]\n",
        "\n",
        "def count_corpus(tokens):\n",
        "    if len(tokens) == 0 or isinstance(tokens[0], list):\n",
        "        tokens = [token for line in tokens for token in line]\n",
        "    return collections.Counter(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.024541,
          "end_time": "2021-04-02T05:53:28.625064",
          "exception": false,
          "start_time": "2021-04-02T05:53:28.600523",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "GLeNMB_nYwQ7"
      },
      "source": [
        "def try_gpu(i=0):\n",
        "    \"\"\"Return gpu(i) if exists, otherwise return cpu().\"\"\"\n",
        "    if torch.cuda.device_count() >= i + 1:\n",
        "        return torch.device(f'cuda:{i}')\n",
        "    return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.026609,
          "end_time": "2021-04-02T05:53:28.711864",
          "exception": false,
          "start_time": "2021-04-02T05:53:28.685255",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "92K_SwJlYwQ8"
      },
      "source": [
        "def truncate_pad(line, num_steps, padding_token):\n",
        "    \"\"\"Truncate or pad sequences.\"\"\"\n",
        "    if len(line) > num_steps:\n",
        "        return line[:num_steps]  # Truncate\n",
        "    return line + [padding_token] * (num_steps - len(line))  # Pad\n",
        "\n",
        "def load_array(data_arrays, batch_size, is_train=True):\n",
        "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
        "    dataset = data.TensorDataset(*data_arrays)\n",
        "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
        "\n",
        "def build_array_nmt(lines, vocab, num_steps):\n",
        "    \"\"\"Transform text sequences of machine translation into minibatches.\"\"\"\n",
        "    lines = [vocab[l] for l in lines]\n",
        "    lines = [l + [vocab['<eos>']] for l in lines]\n",
        "    array = torch.tensor([truncate_pad(l, num_steps, vocab['<pad>']) for l in lines])\n",
        "    valid_len = (array != vocab['<pad>']).type(torch.int32).sum(1)\n",
        "    return array, valid_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.02785,
          "end_time": "2021-04-02T05:53:28.756706",
          "exception": false,
          "start_time": "2021-04-02T05:53:28.728856",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "S6MZZX7aYwQ-"
      },
      "source": [
        "def load_data_nmt(X_train, y_train, batch_size, num_steps, num_examples=600):\n",
        "    \"\"\"Return the iterator and the vocabularies of the translation dataset.\"\"\"\n",
        "    \n",
        "    source = tokenize_hin(X_train)\n",
        "    target = tokenize_eng(y_train)\n",
        "    \n",
        "    src_vocab = Vocab(source, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    tgt_vocab = Vocab(target, min_freq=2, reserved_tokens=['<pad>', '<bos>', '<eos>'])\n",
        "    \n",
        "    src_array, src_valid_len = build_array_nmt(source, src_vocab, num_steps)\n",
        "    tgt_array, tgt_valid_len = build_array_nmt(target, tgt_vocab, num_steps)\n",
        "    \n",
        "    data_arrays = (src_array, src_valid_len, tgt_array, tgt_valid_len)\n",
        "    data_iter = load_array(data_arrays, batch_size)\n",
        "    \n",
        "    return data_iter, src_vocab, tgt_vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "NBHmEBObYwQ_"
      },
      "source": [
        "class DotProductAttention(nn.Module):\n",
        "    \"\"\"Scaled dot product attention.\"\"\"\n",
        "    def __init__(self, dropout, **kwargs):\n",
        "        super(DotProductAttention, self).__init__(**kwargs)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    # Shape of `queries`: (`batch_size`, no. of queries, `d`)\n",
        "    # Shape of `keys`: (`batch_size`, no. of key-value pairs, `d`)\n",
        "    # Shape of `values`: (`batch_size`, no. of key-value pairs, value dimension)\n",
        "    # Shape of `valid_lens`: (`batch_size`,) or (`batch_size`, no. of queries)\n",
        "    def forward(self, queries, keys, values, valid_lens=None):\n",
        "        d = queries.shape[-1]\n",
        "        # Set `transpose_b=True` to swap the last two dimensions of `keys`\n",
        "        scores = torch.bmm(queries, keys.transpose(1, 2)) / math.sqrt(d)\n",
        "        self.attention_weights = masked_softmax(scores, valid_lens)\n",
        "        return torch.bmm(self.dropout(self.attention_weights), values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b87I5Q7hYwQ_"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, key_size, query_size, value_size, num_hiddens,\n",
        "                 num_heads, dropout, bias=False, **kwargs):\n",
        "        super(MultiHeadAttention, self).__init__(**kwargs)\n",
        "        self.num_heads = num_heads\n",
        "        self.attention = DotProductAttention(dropout)\n",
        "        self.W_q = nn.Linear(query_size, num_hiddens, bias=bias)\n",
        "        self.W_k = nn.Linear(2*key_size, num_hiddens, bias=bias)\n",
        "        self.W_v = nn.Linear(2*value_size, num_hiddens, bias=bias)\n",
        "        self.W_o = nn.Linear(num_hiddens, 2*num_hiddens, bias=bias)\n",
        "\n",
        "    def forward(self, queries, keys, values, valid_lens):\n",
        "        # Shape of `queries`, `keys`, or `values`:\n",
        "        # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`)\n",
        "        # After transposing, shape of output `queries`, `keys`, or `values`:\n",
        "        # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
        "        # `num_hiddens` / `num_heads`)\n",
        "        \n",
        "        queries = transpose_qkv(self.W_q(queries), self.num_heads)\n",
        "        keys = transpose_qkv(self.W_k(keys), self.num_heads)\n",
        "        values = transpose_qkv(self.W_v(values), self.num_heads)\n",
        "\n",
        "        if valid_lens is not None:\n",
        "            # On axis 0, copy the first item (scalar or vector) for\n",
        "            # `num_heads` times, then copy the next item, and so on\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, repeats=self.num_heads, dim=0)\n",
        "\n",
        "        # Shape of `output`: (`batch_size` * `num_heads`, no. of queries,\n",
        "        # `num_hiddens` / `num_heads`)\n",
        "        output = self.attention(queries, keys, values, valid_lens)\n",
        "\n",
        "        # Shape of `output_concat`:\n",
        "        # (`batch_size`, no. of queries, `num_hiddens`)\n",
        "        output_concat = transpose_output(output, self.num_heads)\n",
        "        return self.W_o(output_concat)\n",
        "\n",
        "def transpose_qkv(X, num_heads):\n",
        "    # Shape of input `X`:\n",
        "    # (`batch_size`, no. of queries or key-value pairs, `num_hiddens`).\n",
        "    X = X.reshape(X.shape[0], X.shape[1], num_heads, -1)\n",
        "\n",
        "    X = X.permute(0, 2, 1, 3)\n",
        "\n",
        "    # Shape of `output`:\n",
        "    # (`batch_size` * `num_heads`, no. of queries or key-value pairs,\n",
        "    # `num_hiddens` / `num_heads`)\n",
        "    t = X.reshape(-1, X.shape[2], X.shape[3])\n",
        "    return X.reshape(-1, X.shape[2], X.shape[3])\n",
        "\n",
        "def transpose_output(X, num_heads):\n",
        "    \"\"\"Reverse the operation of `transpose_qkv`\"\"\"\n",
        "    X = X.reshape(-1, num_heads, X.shape[1], X.shape[2])\n",
        "    X = X.permute(0, 2, 1, 3)\n",
        "    return X.reshape(X.shape[0], X.shape[1], -1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "rozOyIeJYwRB"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"The base class for the encoder-decoder architecture.\"\"\"\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(EncoderDecoder, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self, enc_X, dec_X, *args):\n",
        "        enc_outputs = self.encoder(enc_X, *args)\n",
        "        (outputs, dec_hidden_st, enc_valid_lens) = self.decoder.init_state(enc_outputs, *args)\n",
        "        return self.decoder(dec_X, (outputs, dec_hidden_st, enc_valid_lens))\n",
        "\n",
        "class Seq2SeqEncoder(nn.Module):\n",
        "    \"\"\"The RNN encoder for sequence to sequence learning.\"\"\"\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers, dropout=0, **kwargs):\n",
        "        super(Seq2SeqEncoder, self).__init__(**kwargs)\n",
        "        # Embedding layer\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size, num_hiddens, num_layers,\n",
        "                          dropout=dropout, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(num_hiddens * 2, num_hiddens)\n",
        "\n",
        "    def forward(self, X, *args):\n",
        "        # The output `X` shape: (`batch_size`, `num_steps`, `embed_size`)\n",
        "        X = self.dropout(self.embedding(X))\n",
        "        # In RNN models, the first axis corresponds to time steps\n",
        "        X = X.permute(1, 0, 2)\n",
        "        # When state is not mentioned, it defaults to zeros\n",
        "        output, hidden_st = self.rnn(X)\n",
        "        concat = torch.cat((hidden_st[0:hidden_st.size(0):2], hidden_st[1:hidden_st.size(0):2]), dim=2)\n",
        "        hidden_st = torch.tanh(self.fc(concat)) \n",
        "        # `output` shape: (`num_steps`, `batch_size`, `2*num_hiddens`)\n",
        "        # `hidden_st` shape: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        return output, hidden_st\n",
        "\n",
        "class Seq2SeqAttentionDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
        "                 dropout=0, **kwargs):\n",
        "        super(Seq2SeqAttentionDecoder, self).__init__(**kwargs)\n",
        "        self.attention = MultiHeadAttention(num_hiddens, num_hiddens, num_hiddens, num_hiddens, 2, dropout)\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
        "        self.rnn = nn.GRU(embed_size + 2*num_hiddens, num_hiddens, num_layers, dropout=dropout)\n",
        "        self.dense = nn.Linear(num_hiddens, vocab_size)\n",
        "\n",
        "    def init_state(self, enc_outputs, enc_valid_lens, *args):\n",
        "        # Shape of `outputs`: (`num_steps`, `batch_size`, `2*num_hiddens`).\n",
        "        # Shape of `hidden_st`: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        outputs, hidden_st = enc_outputs\n",
        "        return (outputs.permute(1, 0, 2), hidden_st, enc_valid_lens)\n",
        "\n",
        "    def forward(self, X, state):\n",
        "        # Shape of `enc_outputs`: (`batch_size`, `num_steps`, `2*num_hiddens`).\n",
        "        # Shape of `hidden_st`: (`num_layers`, `batch_size`, `num_hiddens`)\n",
        "        enc_outputs, hidden_st, enc_valid_lens = state\n",
        "        # Shape of the output `X`: (`num_steps`, `batch_size`, `embed_size`)\n",
        "        X = self.embedding(X).permute(1, 0, 2)\n",
        "        outputs, self._attention_weights = [], []\n",
        "        for x in X:\n",
        "            # Shape of `query`: (`batch_size`, 1, `num_hiddens`)\n",
        "            query = torch.unsqueeze(hidden_st[-1], dim=1)\n",
        "            # Shape of `context`: (`batch_size`, 1, `2*num_hiddens`)\n",
        "            context = self.attention(query, enc_outputs, enc_outputs, enc_valid_lens)\n",
        "            # Concatenate on the feature dimension\n",
        "            x = torch.cat((context, torch.unsqueeze(x, dim=1)), dim=-1)\n",
        "            # Reshape `x` as (1, `batch_size`, `embed_size` + `2*num_hiddens`)\n",
        "            out, hidden_st = self.rnn(x.permute(1, 0, 2), hidden_st)\n",
        "            outputs.append(out)\n",
        "        \n",
        "        # After fully-connected layer transformation, shape of `outputs`:\n",
        "        # (`num_steps`, `batch_size`, `vocab_size`)\n",
        "        outputs = self.dense(torch.cat(outputs, dim=0))\n",
        "        return outputs.permute(1, 0, 2), [\n",
        "            enc_outputs, hidden_st, enc_valid_lens]\n",
        "\n",
        "    def attention_weights(self):\n",
        "        return self._attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.026876,
          "end_time": "2021-04-02T05:53:28.893535",
          "exception": false,
          "start_time": "2021-04-02T05:53:28.866659",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "Yix3-np_YwRD"
      },
      "source": [
        "def sequence_mask(X, valid_len, value=0):\n",
        "    \"\"\"Mask irrelevant entries in sequences.\"\"\"\n",
        "    maxlen = X.size(1)\n",
        "    mask = torch.arange((maxlen), dtype=torch.float32,\n",
        "                        device=X.device)[None, :] < valid_len[:, None]\n",
        "    X[~mask] = value\n",
        "    return X\n",
        "\n",
        "class MaskedSoftmaxCELoss(nn.CrossEntropyLoss):\n",
        "    \"\"\"The softmax cross-entropy loss with masks.\"\"\"\n",
        "\n",
        "    # `pred` shape: (`batch_size`, `num_steps`, `vocab_size`)\n",
        "    # `label` shape: (`batch_size`, `num_steps`)\n",
        "    # `valid_len` shape: (`batch_size`,)\n",
        "    def forward(self, pred, label, valid_len):\n",
        "        weights = torch.ones_like(label)\n",
        "        weights = sequence_mask(weights, valid_len)\n",
        "        self.reduction = 'none'\n",
        "        unweighted_loss = super(MaskedSoftmaxCELoss, self).forward(pred.permute(0, 2, 1), label)\n",
        "        weighted_loss = (unweighted_loss * weights).mean(dim=1)\n",
        "        return weighted_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CqBV_NkJYwRE"
      },
      "source": [
        "def masked_softmax(X, valid_lens):\n",
        "    \"\"\"Perform softmax operation by masking elements on the last axis.\"\"\"\n",
        "    # `X`: 3D tensor, `valid_lens`: 1D or 2D tensor\n",
        "    if valid_lens is None:\n",
        "        return nn.functional.softmax(X, dim=-1)\n",
        "    else:\n",
        "        shape = X.shape\n",
        "        if valid_lens.dim() == 1:\n",
        "            valid_lens = torch.repeat_interleave(valid_lens, shape[1])\n",
        "        else:\n",
        "            valid_lens = valid_lens.reshape(-1)\n",
        "        # On the last axis, replace masked elements with a very large negative\n",
        "        # value, whose exponentiation outputs 0\n",
        "        X = sequence_mask(X.reshape(-1, shape[-1]), valid_lens, value=-1e6)\n",
        "        return nn.functional.softmax(X.reshape(shape), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.032843,
          "end_time": "2021-04-02T05:53:28.988319",
          "exception": false,
          "start_time": "2021-04-02T05:53:28.955476",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "fATgdtQ3YwRF"
      },
      "source": [
        "def train_seq2seq(net, data_iter, lr, num_epochs, tgt_vocab, device):\n",
        "    \"\"\"Train a model for sequence to sequence.\"\"\"\n",
        "    def xavier_init_weights(m):\n",
        "        if type(m) == nn.Linear:\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "        if type(m) == nn.LSTM:\n",
        "            for param in m._flat_weights_names:\n",
        "                if \"weight\" in param:\n",
        "                    nn.init.xavier_uniform_(m._parameters[param])\n",
        "\n",
        "    net.apply(xavier_init_weights)\n",
        "    net.to(device)\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "    loss = MaskedSoftmaxCELoss()\n",
        "    net.train()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        metric = Accumulator(2)  # Sum of training loss, no. of tokens\n",
        "        \n",
        "        for batch in data_iter:\n",
        "            \n",
        "            X, X_valid_len, Y, Y_valid_len = [x.to(device) for x in batch]\n",
        "            bos = torch.tensor([tgt_vocab['<bos>']] * Y.shape[0], device=device).reshape(-1, 1)\n",
        "            \n",
        "            dec_input = torch.cat([bos, Y[:, :-1]], 1)  # Teacher forcing\n",
        "            Y_hat, _ = net(X, dec_input, X_valid_len)\n",
        "            \n",
        "            l = loss(Y_hat, Y, Y_valid_len)\n",
        "            l.sum().backward()  # Make the loss scalar for `backward`\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(net.parameters(), 1)\n",
        "            num_tokens = Y_valid_len.sum()\n",
        "            optimizer.step()\n",
        "            with torch.no_grad():\n",
        "                metric.add(l.sum(), num_tokens)\n",
        "        print(epoch, f'loss {metric[0] / metric[1]:.3f}')\n",
        "    print(f'final loss {metric[0] / metric[1]:.3f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7JEijNqMYwRF"
      },
      "source": [
        "embed_size, num_hiddens, num_layers, dropout = 64, 128, 2, 0.25\n",
        "batch_size, num_steps = 64, 15\n",
        "lr, num_epochs, device = 0.001, 200, try_gpu()\n",
        "\n",
        "\"\"\"\n",
        "# This was used to load train data which was saved using function 'train_validation_split' \n",
        "with open('../input/train-validate/Data/X_train.txt', 'r') as f, open('../input/train-validate/Data/y_train.txt', 'r') as f1:\n",
        "    X_train = f.read().splitlines()\n",
        "    y_train = f1.read().splitlines()\n",
        "\"\"\"\n",
        "# To load all train data\n",
        "csv_file = '../input/hineng/train/train.csv'\n",
        "X_train = [] \n",
        "y_train = []\n",
        "with open(csv_file, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        if(row[0] == ''):\n",
        "            continue\n",
        "        X_train.append(row[1])\n",
        "        y_train.append(row[2])\n",
        "\n",
        "train_iter, src_vocab, tgt_vocab = load_data_nmt(X_train, y_train, batch_size, num_steps)\n",
        "\n",
        "encoder = Seq2SeqEncoder(len(src_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "decoder = Seq2SeqAttentionDecoder(len(tgt_vocab), embed_size, num_hiddens, num_layers, dropout)\n",
        "net = EncoderDecoder(encoder, decoder)\n",
        "print(\"Training Starts...\")\n",
        "\n",
        "st = time.time()\n",
        "train_seq2seq(net, train_iter, lr, num_epochs, tgt_vocab, device)\n",
        "ed = time.time()\n",
        "print('Time taken by model : ', ed-st)\n",
        "torch.save(net.state_dict(), './train_model_fnl.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 0.034782,
          "end_time": "2021-04-02T08:35:18.868933",
          "exception": false,
          "start_time": "2021-04-02T08:35:18.834151",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "USr6p4kfYwRG"
      },
      "source": [
        "def predict_seq2seq(net, src_sentence, src_vocab, tgt_vocab, num_steps, device, save_attention_weights=False):\n",
        "    \"\"\"Predict for sequence to sequence.\"\"\"\n",
        "    \n",
        "    # Set `net` to eval mode for inference\n",
        "    net.eval()\n",
        "    tkns = tokenize_hin([src_sentence])\n",
        "    tkns = tkns[0]\n",
        "    src_tokens = src_vocab[tkns] + [src_vocab['<eos>']]\n",
        "    enc_valid_len = torch.tensor([len(src_tokens)], device=device)\n",
        "    src_tokens = truncate_pad(src_tokens, num_steps, src_vocab['<pad>'])\n",
        "    \n",
        "    # Add the batch axis\n",
        "    enc_X = torch.unsqueeze(torch.tensor(src_tokens, dtype=torch.long, device=device), dim=0)\n",
        "    enc_outputs = net.encoder(enc_X, enc_valid_len)\n",
        "    dec_st = net.decoder.init_state(enc_outputs, enc_valid_len)\n",
        "    \n",
        "    # Add the batch axis\n",
        "    dec_X = torch.unsqueeze(torch.tensor([tgt_vocab['<bos>']], dtype=torch.long, device=device), dim=0)\n",
        "    output_seq, attention_weight_seq = [], []\n",
        "    \n",
        "    for _ in range(num_steps):\n",
        "        Y, dec_st = net.decoder(dec_X, dec_st)\n",
        "        \n",
        "        # We use the token with the highest prediction likelihood as the input\n",
        "        # of the decoder at the next time step\n",
        "        dec_X = Y.argmax(dim=2)\n",
        "        pred = dec_X.squeeze(dim=0).type(torch.int32).item()\n",
        "        \n",
        "        if save_attention_weights:\n",
        "            attention_weight_seq.append(net.decoder.attention_weights)\n",
        "        \n",
        "        # Once the end-of-sequence token is predicted, the generation of the\n",
        "        # output sequence is complete\n",
        "        if pred == tgt_vocab['<eos>']:\n",
        "            break\n",
        "        output_seq.append(pred)\n",
        "    \n",
        "    return ' '.join(tgt_vocab.to_tokens(output_seq)), attention_weight_seq\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 167.345995,
          "end_time": "2021-04-02T08:38:06.456207",
          "exception": false,
          "start_time": "2021-04-02T08:35:19.110212",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "BropZHVAYwRH"
      },
      "source": [
        "# Load validation set\n",
        "X_validate = []\n",
        "y_validate = []\n",
        "with open('../input/train-validate/Data/X_validate.txt', 'r') as f, open('../input/train-validate/Data/y_validate.txt', 'r') as f1:\n",
        "    X_validate = f.read().splitlines()\n",
        "    y_validate = f1.read().splitlines()\n",
        "\n",
        "# Prediction on validation set \n",
        "predict = []\n",
        "for hind, eng in zip(X_validate[:20],y_validate[:20]):\n",
        "    translation, attention_weight_seq = predict_seq2seq(net, hind, src_vocab, tgt_vocab, num_steps, device)\n",
        "    predict.append(translation)\n",
        "\n",
        "# Printing sample predictions\n",
        "i = 0\n",
        "while i < 20:\n",
        "    print(X_validate[i])\n",
        "    print(y_validate[i])\n",
        "    print(predict[i])\n",
        "    print(\"\\n\")\n",
        "    i += 1\n",
        "\n",
        "# Save predictions of validation set\n",
        "with open('predict.txt', 'w') as f:\n",
        "    for row1 in predict:\n",
        "        f.write(row1 + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "papermill": {
          "duration": 31.60771,
          "end_time": "2021-04-02T08:39:11.624396",
          "exception": false,
          "start_time": "2021-04-02T08:38:40.016686",
          "status": "completed"
        },
        "tags": [],
        "trusted": true,
        "id": "B3XLaZT8YwRH"
      },
      "source": [
        "# Predicting on test data and save in answer.txt\n",
        "hindi_tst = []\n",
        "csv_file = '../input/tstphase/testhindistatements.csv'\n",
        "with open(csv_file, 'r') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for row in reader:\n",
        "        if(row[0] == ''):\n",
        "            continue\n",
        "        hindi_tst.append(row[2])\n",
        "\n",
        "answer = []\n",
        "for hind in hindi_tst:\n",
        "    translation, attention_weight_seq = predict_seq2seq(net, hind, src_vocab, tgt_vocab, num_steps, device)\n",
        "    answer.append(translation)\n",
        "\n",
        "with open('answer.txt', 'w') as f:\n",
        "    for row1 in answer:\n",
        "        f.write(row1 + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
